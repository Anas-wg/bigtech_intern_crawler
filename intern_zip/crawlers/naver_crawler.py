# crawlers/naver_crawler.py
from bs4 import BeautifulSoup
import re
from .base_crawler import BaseCrawler

class NaverCrawler(BaseCrawler):
    def __init__(self):
        super().__init__("https://recruit.navercorp.com")

    def parse(self, html):
        """ ë„¤ì´ë²„ ì±„ìš© ê³µê³ ë¥¼ í¬ë¡¤ë§í•˜ëŠ” í•¨ìˆ˜ """
        soup = BeautifulSoup(html, "html.parser")
        notices = soup.select(".card_wrap > .card_list > li")
        base_url = f"{self.base_url}/rcrt/view.do?annoId="

        job_links = []
        for notice in notices:
            tag_element = notice.select_one("a")
            if tag_element:
                notice_title = tag_element.select_one("h4").text.strip()  # ì œëª© ê°€ì ¸ì˜¤ê¸°
                notice_info = tag_element.select_one("dl")

                notice_period = None  # ëª¨ì§‘ ê¸°ê°„ ê¸°ë³¸ê°’ ì„¤ì •
                notice_part = None
                if notice_info:
                    dt_elements = notice_info.select("dt")  # ëª¨ë“  dt íƒœê·¸ ê°€ì ¸ì˜¤ê¸°
                    dd_elements = notice_info.select("dd")  # ëª¨ë“  dd íƒœê·¸ ê°€ì ¸ì˜¤ê¸°

                    # dtì™€ ddê°€ ì§ì„ ì´ë£¨ë¯€ë¡œ, "ëª¨ì§‘ ê¸°ê°„"ì„ ì°¾ì•„ í•´ë‹¹ dd ê°’ì„ ê°€ì ¸ì˜´
                    for dt, dd in zip(dt_elements, dd_elements):
                        if dt.text.strip() == "ëª¨ì§‘ ë¶„ì•¼":
                            notice_part = dd.text.strip()
                        if dt.text.strip() == "ëª¨ì§‘ ê¸°ê°„":  # "ëª¨ì§‘ ê¸°ê°„"ì¸ dt ì°¾ê¸°
                            notice_period = dd.text.strip()  # í•´ë‹¹í•˜ëŠ” ddì˜ í…ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
                            break  # ì°¾ìœ¼ë©´ ë°˜ë³µ ì¢…ë£Œ
                
                onclick_attr = tag_element.get("onclick")
                notice_url = None  # URL ê¸°ë³¸ê°’ ì„¤ì •
                if onclick_attr:
                    match = re.search(r"show\('(\d+)'\)", onclick_attr)
                    if match:
                        notice_number = match.group(1)
                        notice_url = base_url + notice_number

                # ğŸ”¹ ëª¨ì§‘ ê¸°ê°„ì„ í¬í•¨í•´ ë”•ì…”ë„ˆë¦¬ ì €ì¥
                job_links.append({
                    "notice_url": notice_url,
                    "title": notice_title,
                    "period": notice_period,  # ëª¨ì§‘ ê¸°ê°„ ì¶”ê°€
                })

        return job_links


    def crawl(self):
        """ ë„¤ì´ë²„ ì±„ìš© ê³µê³  ë¦¬ìŠ¤íŠ¸ í¬ë¡¤ë§ """
        url = "https://recruit.navercorp.com/rcrt/list.do?subJobCdArr=1010001%2C1010002%2C1010003%2C1010004%2C1010005%2C1010006%2C1010007%2C1010008%2C1010020%2C1020001%2C1030001%2C1030002%2C1040001%2C1050001%2C1050002%2C1060001&sysCompanyCdArr=&empTypeCdArr=0040"
        html = self.get_html(url)
        if html:
            return self.parse(html)
        return []
